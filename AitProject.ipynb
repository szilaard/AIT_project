{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/szilaard/AIT_project/blob/main/AitProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5EuuKNSnR8YU"
   },
   "source": [
    "# AIT Deep Learning Project - Music genre classification based on audio\n",
    "\n",
    "Péter Czumbel, Szilárd Horváth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "o5TQ_zjER30L"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import librosa\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from IPython.display import display\n",
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using the GTZAN dataset, which consists of 1000 audio tracks each 30 seconds long. It contains 10 genres, each represented by 100 tracks. The tracks are all 22050Hz Mono 16-bit audio files in .wav format. However, downloading the GTZAN dataset from tensorflow datasets doesn't work, the URL times out, \n",
    "(see: https://github.com/tensorflow/datasets/issues/4090), therefore we are using [this](https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification) version of the dataset from kaggle instead.<br>\n",
    "After downloading the dataset from Kaggle, extract the Data folder and place it into the projects root directory, if you wish to run the notebook yourself.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download the dataset from kaggle, run the block below and upload your own kaggle API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q kaggle\n",
    "from google.colab import files\n",
    "files.upload()\n",
    "! mkdir ~/.kaggle\n",
    "! cp kaggle.json ~/.kaggle/\n",
    "! chmod 600 ~/.kaggle/kaggle.json\n",
    "! kaggle datasets download -d andradaolteanu/gtzan-dataset-music-genre-classification\n",
    "! unzip gtzan-dataset-music-genre-classification.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we read all the data from the directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = glob(\"Data/genres_original/*/*.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting some variables based on the dataset description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 22050   # sampling frequency\n",
    "duration = 30         # length of the tracks in seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 100 tracks of each genre, and our dataset is ordered, so if we check every 100th track, we can see all the different genres.<br>\n",
    "Example track for each genre:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(audio_files[i*100].split(\"\\\\\")[1])\n",
    "    display(Audio(audio_files[i*100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Plotting the waveforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the waveforms of different music genres, we can see that classifying most of the genres would probably be possible even by only using the waveform, however some genres, like country and metal can look quite similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 7))\n",
    "fig.tight_layout()\n",
    "rows = 2\n",
    "columns = 5\n",
    "for i in range(1, columns * rows + 1):\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    signal, sr = librosa.load(audio_files[(i-1)*100], sr=sample_rate)\n",
    "    librosa.display.waveshow(signal, sr=sample_rate)\n",
    "    plt.title(audio_files[(i-1)*100].split(\"\\\\\")[1])\n",
    "    plt.xlabel(\"\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Plotting the MFCCs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting variables for calculating the MFCCs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft = 2048          # number of samples per fft - the size of the window when performing an fft\n",
    "n_mfcc = 50           # number of extracted coefficients\n",
    "hop_length = 512      # the amount we shift with each fft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the MFCCs of different genres yields more easily differentiable data for each genre. We will be using this version of the data to train our deep neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 7))\n",
    "fig.tight_layout()\n",
    "rows = 2\n",
    "columns = 5\n",
    "for i in range(1, columns * rows + 1):\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    signal, sr = librosa.load(audio_files[(i-1)*100], sr=sample_rate)\n",
    "    mfcc = librosa.feature.mfcc(y=signal, sr=sample_rate, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "    librosa.display.specshow(mfcc, sr=sample_rate, hop_length=hop_length)\n",
    "    plt.title(audio_files[(i-1)*100].split(\"\\\\\")[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Splitting the tracks to segments and calculating MFCCs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a data structure for the mappings, the raw mfcc data and the labels. This way we can save the preprocessed data as a JSON file later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"mapping\": [],  # mapping the names of the genres to indexes 0 to 9\n",
    "    \"mfcc\": [],     # array containing the mfcc arrays of the track segments\n",
    "    \"labels\": []    # array of the genre labels of the track segments\n",
    "}   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define these parameters so we can finetune them if needed in the future. These parameters are needed so we will get uniform shape outputs after the sampling and the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_segments = 10      # the number of segments we want to split each track\n",
    "samples_per_track = sample_rate * duration  # how many samples do we get from each track\n",
    "samples_per_segment=int(samples_per_track/number_of_segments)    # how many samples are there in a segment\n",
    "num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length)   # this is to check if the output has the correct dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next part we separate our audio data into segments, then we use mel frequency cepstral coefficients (MFCCs) on them. This transforms our data closer to what humans would hear/notice listening to the music."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pczum\\AppData\\Local\\Temp\\ipykernel_28488\\3083834638.py:10: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  signal, sr = librosa.load(audio_file)\n",
      "d:\\programs\\anaconda3\\envs\\ait\\lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    }
   ],
   "source": [
    "shuffle(audio_files)    # the audio files are ordered by category, its easier to shuffle them here while we only have to shuffle one array\n",
    "for audio_file in audio_files:\n",
    "    # cutting the name of the genre from the filename\n",
    "    genre = audio_file.split(\"\\\\\")[1]\n",
    "    # adding genre to mapping if its not already there\n",
    "    if genre not in data[\"mapping\"]:      \n",
    "        data[\"mapping\"].append(genre) \n",
    "    try:\n",
    "        # reading signal and sample rate from the file\n",
    "        signal, sr = librosa.load(audio_file) \n",
    "    except:\n",
    "        #there are some corrupted/non readable files so we dont process them\n",
    "        continue\n",
    "        \n",
    "    # we dont have much data, so we split the tracks into segments to increase our training data\n",
    "    for i in range(number_of_segments):\n",
    "        # calculating start and finish index of the segment\n",
    "        start = samples_per_segment * i\n",
    "        end = start + samples_per_segment\n",
    "        # Calculating the mfcc of the segment\n",
    "        mfcc = librosa.feature.mfcc(y=signal[start:end], sr=sample_rate, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "        mfcc = mfcc.T\n",
    "        # Some tracks are shorter than 30 seconds, so we have segments with incorrect length. We filter those out here\n",
    "        if len(mfcc) == num_mfcc_vectors_per_segment:\n",
    "            # Adding the mfcc and label to our data\n",
    "            data[\"mfcc\"].append(mfcc)\n",
    "            data[\"labels\"].append(data[\"mapping\"].index(genre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We transform the created lists into numpy arrays, so they are easier to handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"mfcc\"] = np.array(data[\"mfcc\"], dtype=np.float32)\n",
    "data[\"labels\"] = np.array(data[\"labels\"], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Flattening the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We flatten the data to make it into a one-dimensional array insted of a 2D array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9986, 130, 50)\n"
     ]
    }
   ],
   "source": [
    "print(data[\"mfcc\"].shape)\n",
    "flattened_dim=np.prod(data[\"mfcc\"].shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[\"mfcc\"] = data[\"mfcc\"].reshape(-1,flattened_dim)\n",
    "\n",
    "#data[\"mfcc\"] = data[\"mfcc\"].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Splitting training, testing and validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We separate our data into training, validation and test datasets, we define the ratios so we can fine tune them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_length = len(data[\"mfcc\"])\n",
    "train_ratio = 0.7\n",
    "valid_ratio = 0.2\n",
    "test_ratio = 0.1\n",
    "\n",
    "train_size = int(train_ratio*data_length)\n",
    "valid_size = int(valid_ratio*data_length)\n",
    "test_size = int(test_ratio*data_length)\n",
    "\n",
    "X_train = data[\"mfcc\"][:train_size]\n",
    "Y_train = data[\"labels\"][:train_size]\n",
    "X_valid = data[\"mfcc\"][train_size:train_size+valid_size]\n",
    "Y_valid = data[\"labels\"][train_size:train_size+valid_size]\n",
    "X_test = data[\"mfcc\"][train_size+valid_size:]\n",
    "Y_test = data[\"labels\"][train_size+valid_size:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the mean and variance of the training data, then use these values to standerdize the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.asarray(X_train)\n",
    "Y_train=np.asarray(Y_train)\n",
    "X_valid=np.asarray(X_valid)\n",
    "Y_valid=np.asarray(Y_valid)\n",
    "X_test=np.asarray(X_test)\n",
    "Y_test=np.asarray(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(X_train, axis=0)\n",
    "std  = np.std(X_train, axis=0, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train - mean) / std\n",
    "X_valid = (X_valid - mean) / std\n",
    "X_test  = (X_test - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Encoding the labels and performing checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check if each data set has the same number of categories in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data has the same number of classes, as the training data: True\n",
      "Test data has the same number of classes, as the training data: True\n"
     ]
    }
   ],
   "source": [
    "nb_classes = len(np.unique(Y_train))\n",
    "print(\"Validation data has the same number of classes, as the training data:\", nb_classes == len(np.unique(Y_valid)))\n",
    "print(\"Test data has the same number of classes, as the training data:\", nb_classes == len(np.unique(Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We change the dense representation of the classes to one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = to_categorical(Y_train)\n",
    "Y_valid = to_categorical(Y_valid)\n",
    "Y_test  = to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final check if the data has the right shape, mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of the training, validation and test input data: (6990, 130, 50) (1997, 130, 50) (999, 130, 50)\n",
      "Shapes of the training, validation and test output data: (6990, 10) (1997, 10) (999, 10)\n",
      "Mean values of the training, validation and test input data: 8.086974e-09 -0.007472902 0.008522864\n",
      "Standard deviation of the training, validation and test input data: 0.9999996 1.0180941 1.0498854\n"
     ]
    }
   ],
   "source": [
    "print(\"Shapes of the training, validation and test input data:\", X_train.shape, X_valid.shape, X_test.shape)\n",
    "print(\"Shapes of the training, validation and test output data:\", Y_train.shape, Y_valid.shape, Y_test.shape)\n",
    "print(\"Mean values of the training, validation and test input data:\", X_train.mean(), X_valid.mean(), X_test.mean())\n",
    "print(\"Standard deviation of the training, validation and test input data:\", X_train.std(), X_valid.std(), X_test.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([np.array(val) for val in X_train])\n",
    "Y_train = np.array([np.array(val) for val in Y_train])\n",
    "\n",
    "X_train = tf.cast(X_train , dtype=tf.float32)\n",
    "Y_train = tf.cast(Y_train , dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Models\n",
    "For models we decided to use..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "#from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Earlystopping for both of our models, with the same parameter. We restore the best weight in the end of the training and we use a patience of 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    min_delta=0,\n",
    "    patience=5,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    "    start_from_epoch=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first model is an LSTM model. We chose LSTM becasue it is a useful model for timeseries, like music. In the model we stacked multiple LSTMs and between them we put DropOut layers to minimize overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(80, input_shape=(X_train.shape[-2], X_train.shape[-1]),return_sequences=True))\n",
    "#lstm_model.add(Dropout(0.2))\n",
    "#lstm_model.add(LSTM(80, input_shape=(X_train.shape[-2], X_train.shape[-1]),return_sequences=True))\n",
    "lstm_model.add(LSTM(100, input_shape=(X_train.shape[-2], X_train.shape[-1])))\n",
    "lstm_model.add(Dropout(0.2))\n",
    "lstm_model.add(Dense(35, activation='selu',kernel_initializer='he_normal'))\n",
    "lstm_model.add(Dropout(0.35))\n",
    "lstm_model.add(Dense(nb_classes))\n",
    "lstm_model.add(Activation('softmax')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because it is a multi-class classification task we use categorical crossentropy as loss function. We tried different optimizers and we chose ..... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_history = lstm_model.fit(X_train, Y_train,\n",
    "              batch_size=256,\n",
    "              epochs=40,\n",
    "              validation_data=(X_valid, Y_valid),\n",
    "              verbose=1, \n",
    "              callbacks=es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_preds = lstm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(np.argmax(Y_test,1),np.argmax(lstm_preds,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf=confusion_matrix(np.argmax(Y_test,1),np.argmax(lstm_preds,1))\n",
    "sns.heatmap(conf, annot=True, fmt='d', vmax=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv2D(32, (3, 3), activation='relu',kernel_initializer=HeNormal, input_shape=(32, 32, 3)))\n",
    "cnn_model.add(BatchNormalization())\n",
    "#cnn_model.add(Dropout(0.4))\n",
    "cnn_model.add(MaxPool2D((2, 2)))\n",
    "cnn_model.add(Conv2D(64, (3, 3), activation='relu',kernel_initializer=HeNormal))\n",
    "cnn_model.add(BatchNormalization())\n",
    "cnn_model.add(Dropout(0.4))\n",
    "cnn_model.add(MaxPool2D((2, 2)))\n",
    "cnn_model.add(Conv2D(64, (3, 3), activation='relu',kernel_initializer=HeNormal))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "cnn_model.add(BatchNormalization())\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(64, activation='relu',kernel_initializer=HeNormal))\n",
    "cnn_model.add(Dropout(0.3))\n",
    "cnn_model.add(Dense(nb_classes,activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_history = cnn_model.fit(X_train,\n",
    "                    Y_train,\n",
    "                    epochs=40,\n",
    "                    batch_size=64,  \n",
    "                    validation_data=(X_valid, Y_valid),\n",
    "                    verbose=1, \n",
    "                    callbacks=es\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_preds = cnn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(np.argmax(Y_test,1),np.argmax(cnn_preds,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf=confusion_matrix(np.argmax(Y_test,1),np.argmax(cnn_preds,1))\n",
    "sns.heatmap(conf, annot=True, fmt='d', vmax=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2_model = Sequential()\n",
    "cnn2_model.add(Conv1D(filters=20, kernel_size=48, activation='selu', kernel_initializer='he_normal', input_shape=(X_train.shape[-2],X_train.shape[-1]),padding='same'))\n",
    "cnn2_model.add(MaxPooling1D())\n",
    "cnn2_model.add(Dropout(0.4))  \n",
    "cnn2_model.add(Conv1D(filters=20, kernel_size=48, activation='selu', kernel_initializer='he_normal'))\n",
    "cnn2_model.add(Dropout(0.4))\n",
    "cnn2_model.add(LSTM(25, input_shape=(X_train.shape[-2], X_train.shape[-1]),return_sequences=True))\n",
    "cnn2_model.add(LSTM(20, input_shape=(X_train.shape[-2], X_train.shape[-1])))\n",
    "cnn2_model.add(Dropout(0.4))\n",
    "cnn2_model.add(Dense(35, activation='selu',kernel_initializer='he_normal'))\n",
    "cnn2_model.add(Dropout(0.3))\n",
    "cnn2_model.add(Dense(nb_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2_history = cnn2_model.fit(X_train,\n",
    "                    Y_train,\n",
    "                    epochs=80,\n",
    "                    batch_size=128,  \n",
    "                    validation_data=(X_valid, Y_valid),\n",
    "                    verbose=1, \n",
    "                    callbacks=es\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([6990, 130, 50])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Model(tf.keras.Model):\n",
    "    def __init__(self, size, N, output_dim=10):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.N = N\n",
    "\n",
    "        self.lstm_layers = [tf.keras.layers.LSTM(self.size, return_sequences=True) for _ in range(self.N)]\n",
    "        self.lstm_final = tf.keras.layers.LSTM(self.size, return_sequences=False)\n",
    "        self.dense1 = tf.keras.layers.Dense(60, activation='relu',kernel_initializer='he_normal')\n",
    "        self.dense2 = tf.keras.layers.Dense(output_dim, activation='softmax',kernel_initializer='he_normal')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        #for layer in self.lstm_layers:\n",
    "        #    x = layer(x)\n",
    "        x = self.lstm_final(x)\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        x = self.dense1(x)\n",
    "        return self.dense2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM_Model(60, 2, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.build(input_shape=(None, X_train.shape[-2], X_train.shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lstm__model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_16 (LSTM)              multiple                  0 (unused)\n",
      "                                                                 \n",
      " lstm_17 (LSTM)              multiple                  0 (unused)\n",
      "                                                                 \n",
      " lstm_18 (LSTM)              multiple                  26640     \n",
      "                                                                 \n",
      " dense_22 (Dense)            multiple                  3660      \n",
      "                                                                 \n",
      " dense_23 (Dense)            multiple                  610       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,910\n",
      "Trainable params: 30,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', mode='auto', verbose=1, patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "437/437 [==============================] - 6s 10ms/step - loss: 1.6423 - accuracy: 0.4119 - val_loss: 1.5076 - val_accuracy: 0.4607\n",
      "Epoch 2/40\n",
      "437/437 [==============================] - 4s 8ms/step - loss: 1.1841 - accuracy: 0.5810 - val_loss: 1.5717 - val_accuracy: 0.4702\n",
      "Epoch 3/40\n",
      "437/437 [==============================] - 4s 8ms/step - loss: 0.9775 - accuracy: 0.6629 - val_loss: 1.4289 - val_accuracy: 0.5173\n",
      "Epoch 4/40\n",
      "437/437 [==============================] - 4s 8ms/step - loss: 0.8247 - accuracy: 0.7176 - val_loss: 1.4453 - val_accuracy: 0.5413\n",
      "Epoch 5/40\n",
      "437/437 [==============================] - 4s 8ms/step - loss: 0.6966 - accuracy: 0.7639 - val_loss: 1.4755 - val_accuracy: 0.5528\n",
      "Epoch 6/40\n",
      "437/437 [==============================] - 4s 8ms/step - loss: 0.6225 - accuracy: 0.7840 - val_loss: 1.4469 - val_accuracy: 0.5709\n",
      "Epoch 7/40\n",
      "437/437 [==============================] - 4s 8ms/step - loss: 0.5301 - accuracy: 0.8193 - val_loss: 1.5320 - val_accuracy: 0.5709\n",
      "Epoch 8/40\n",
      "437/437 [==============================] - 4s 8ms/step - loss: 0.4670 - accuracy: 0.8423 - val_loss: 1.5263 - val_accuracy: 0.5884\n",
      "Epoch 8: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e818f15000>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.fit(X_train, Y_train, epochs=40, batch_size=16, validation_data=(X_valid, Y_valid), verbose=1, callbacks=es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.expand_dims(X_train, axis=-1)\n",
    "X_valid = tf.expand_dims(X_valid, axis=-1)\n",
    "X_test = tf.expand_dims(X_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONV_Model(tf.keras.Model):\n",
    "    def __init__(self, output_dim=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu', input_shape=(X_train.shape[1],X_train.shape[2], 1),padding='valid')\n",
    "        self.conv3 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='valid')\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, activation='relu', padding='valid')\n",
    "        self.ap = tf.keras.layers.AveragePooling2D(pool_size=3, strides=2, padding='same')\n",
    "        self.dense1 = tf.keras.layers.Dense(256, activation='relu',kernel_initializer='he_normal')\n",
    "        self.dense2 = tf.keras.layers.Dense(128, activation='relu',kernel_initializer='he_normal')\n",
    "        self.dense3 = tf.keras.layers.Dense(output_dim, activation='softmax', kernel_initializer='zeros')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.conv3(x)\n",
    "        x = self.ap(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.ap(x)\n",
    "        x = self.conv2(x)\n",
    "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return self.dense3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'x' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m conv \u001b[39m=\u001b[39m CONV_Model(\u001b[39m10\u001b[39m)\n\u001b[0;32m      2\u001b[0m conv\u001b[39m.\u001b[39mcompile(optimizer \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m----> 3\u001b[0m conv\u001b[39m.\u001b[39;49mbuild(input_shape\u001b[39m=\u001b[39;49m(\u001b[39mNone\u001b[39;49;00m, X_train\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m], X_train\u001b[39m.\u001b[39;49mshape[\u001b[39m2\u001b[39;49m], \u001b[39m1\u001b[39;49m))\n",
      "File \u001b[1;32md:\\programs\\anaconda3\\envs\\ait\\lib\\site-packages\\keras\\engine\\training.py:509\u001b[0m, in \u001b[0;36mModel.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    504\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    505\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can only call `build()` on a model if its \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    506\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`call()` method accepts an `inputs` argument.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    507\u001b[0m     )\n\u001b[0;32m    508\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 509\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall(x, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    510\u001b[0m \u001b[39mexcept\u001b[39;00m (tf\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mInvalidArgumentError, \u001b[39mTypeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    511\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    512\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou cannot build your model by calling `build` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mif your layers do not support float type inputs. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`call` is: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    518\u001b[0m     )\n",
      "Cell \u001b[1;32mIn[50], line 13\u001b[0m, in \u001b[0;36mCONV_Model.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs):\n\u001b[1;32m---> 13\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x)\n\u001b[0;32m     14\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv3(x)\n\u001b[0;32m     15\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39map(x)\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'x' referenced before assignment"
     ]
    }
   ],
   "source": [
    "conv = CONV_Model(10)\n",
    "conv.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "conv.build(input_shape=(None, X_train.shape[1], X_train.shape[2], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "437/437 [==============================] - 62s 137ms/step - loss: 52.1645 - accuracy: 0.3678 - val_loss: 64.2779 - val_accuracy: 0.2178\n",
      "Epoch 2/40\n",
      "437/437 [==============================] - 59s 135ms/step - loss: 50.1064 - accuracy: 0.4876 - val_loss: 86.2102 - val_accuracy: 0.4422\n",
      "Epoch 3/40\n",
      "437/437 [==============================] - 59s 136ms/step - loss: 46.3262 - accuracy: 0.5750 - val_loss: 73.7838 - val_accuracy: 0.4387\n",
      "Epoch 4/40\n",
      "437/437 [==============================] - 59s 136ms/step - loss: 43.9841 - accuracy: 0.6468 - val_loss: 86.5819 - val_accuracy: 0.3736\n",
      "Epoch 5/40\n",
      "180/437 [===========>..................] - ETA: 31s - loss: 34.4298 - accuracy: 0.7260"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m conv\u001b[39m.\u001b[39;49mfit(X_train, Y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m40\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_valid, Y_valid), verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49mes)\n",
      "File \u001b[1;32md:\\programs\\anaconda3\\envs\\ait\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\programs\\anaconda3\\envs\\ait\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32md:\\programs\\anaconda3\\envs\\ait\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\programs\\anaconda3\\envs\\ait\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\programs\\anaconda3\\envs\\ait\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32md:\\programs\\anaconda3\\envs\\ait\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32md:\\programs\\anaconda3\\envs\\ait\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\programs\\anaconda3\\envs\\ait\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32md:\\programs\\anaconda3\\envs\\ait\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "conv.fit(X_train, Y_train, epochs=40, batch_size=16, validation_data=(X_valid, Y_valid), verbose=1, callbacks=es)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPeiS6h3OAXVnkq67zCtqPm",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
