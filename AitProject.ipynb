{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/szilaard/AIT_project/blob/main/AitProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5EuuKNSnR8YU"
   },
   "source": [
    "# AIT Deep Learning Project - Music genre classification based on audio\n",
    "\n",
    "Péter Czumbel, Szilárd Horváth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o5TQ_zjER30L"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import librosa\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from IPython.display import display\n",
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using the GTZAN dataset, which consists of 1000 audio tracks each 30 seconds long. It contains 10 genres, each represented by 100 tracks. The tracks are all 22050Hz Mono 16-bit audio files in .wav format. However, downloading the GTZAN dataset from tensorflow datasets doesn't work, the URL times out, \n",
    "(see: https://github.com/tensorflow/datasets/issues/4090), therefore we are using [this](https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification) version of the dataset from kaggle instead.<br>\n",
    "After downloading the dataset from Kaggle, extract the Data folder and place it into the projects root directory, if you wish to run the notebook yourself.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download the dataset from kaggle, run the block below and upload your own kaggle API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q kaggle\n",
    "from google.colab import files\n",
    "files.upload()\n",
    "! mkdir ~/.kaggle\n",
    "! cp kaggle.json ~/.kaggle/\n",
    "! chmod 600 ~/.kaggle/kaggle.json\n",
    "! kaggle datasets download -d andradaolteanu/gtzan-dataset-music-genre-classification\n",
    "! unzip gtzan-dataset-music-genre-classification.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we read all the data from the directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = glob(\"Data/genres_original/*/*.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting some variables based on the dataset description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 22050   # sampling frequency\n",
    "duration = 30         # length of the tracks in seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 100 tracks of each genre, and our dataset is ordered, so if we check every 100th track, we can see all the different genres.<br>\n",
    "Example track for each genre:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(audio_files[i*100].split(\"\\\\\")[1])\n",
    "    display(Audio(audio_files[i*100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Plotting the waveforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the waveforms of different music genres, we can see that classifying most of the genres would probably be possible even by only using the waveform, however some genres, like country and metal can look quite similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 7))\n",
    "fig.tight_layout()\n",
    "rows = 2\n",
    "columns = 5\n",
    "for i in range(1, columns * rows + 1):\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    signal, sr = librosa.load(audio_files[(i-1)*100], sr=sample_rate)\n",
    "    librosa.display.waveshow(signal, sr=sample_rate)\n",
    "    plt.title(audio_files[(i-1)*100].split(\"\\\\\")[1])\n",
    "    plt.xlabel(\"\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Plotting the MFCCs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting variables for calculating the MFCCs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft = 2048          # number of samples per fft - the size of the window when performing an fft\n",
    "n_mfcc = 13           # number of extracted coefficients\n",
    "hop_length = 512      # the amount we shift with each fft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the MFCCs of different genres yields more easily differentiable data for each genre. We will be using this version of the data to train our deep neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 7))\n",
    "fig.tight_layout()\n",
    "rows = 2\n",
    "columns = 5\n",
    "for i in range(1, columns * rows + 1):\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    signal, sr = librosa.load(audio_files[(i-1)*100], sr=sample_rate)\n",
    "    mfcc = librosa.feature.mfcc(y=signal, sr=sample_rate, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "    librosa.display.specshow(mfcc, sr=sample_rate, hop_length=hop_length)\n",
    "    plt.title(audio_files[(i-1)*100].split(\"\\\\\")[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Splitting the tracks to segments and calculating MFCCs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a data structure for the mappings, the raw mfcc data and the labels. This way we can save the preprocessed data as a JSON file later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"mapping\": [],  # mapping the names of the genres to indexes 0 to 9\n",
    "    \"mfcc\": [],     # array containing the mfcc arrays of the track segments\n",
    "    \"labels\": []    # array of the genre labels of the track segments\n",
    "}   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define these parameters so we can finetune them if needed in the future. These parameters are needed so we will get uniform shape outputs after the sampling and the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_segments = 5      # the number of segments we want to split each track\n",
    "samples_per_track = sample_rate * duration  # how many samples do we get from each track\n",
    "samples_per_segment=int(samples_per_track/number_of_segments)    # how many samples are there in a segment\n",
    "num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length)   # this is to check if the output has the correct dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next part we separate our audio data into segments, then we use mel frequency cepstral coefficients (MFCCs) on them. This transforms our data closer to what humans would hear/notice listening to the music."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle(audio_files)    # the audio files are ordered by category, its easier to shuffle them here while we only have to shuffle one array\n",
    "for audio_file in audio_files:\n",
    "    # cutting the name of the genre from the filename\n",
    "    genre = audio_file.split(\"\\\\\")[1]\n",
    "    # adding genre to mapping if its not already there\n",
    "    if genre not in data[\"mapping\"]:      \n",
    "        data[\"mapping\"].append(genre) \n",
    "    try:\n",
    "        # reading signal and sample rate from the file\n",
    "        signal, sr = librosa.load(audio_file) \n",
    "    except:\n",
    "        #there are some corrupted/non readable files so we dont process them\n",
    "        continue\n",
    "        \n",
    "    # we dont have much data, so we split the tracks into segments to increase our training data\n",
    "    for i in range(number_of_segments):\n",
    "        # calculating start and finish index of the segment\n",
    "        start = samples_per_segment * i\n",
    "        end = start + samples_per_segment\n",
    "        # Calculating the mfcc of the segment\n",
    "        mfcc = librosa.feature.mfcc(y=signal[start:end], sr=sample_rate, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "        mfcc = mfcc.T\n",
    "        # Some tracks are shorter than 30 seconds, so we have segments with incorrect length. We filter those out here\n",
    "        if len(mfcc) == num_mfcc_vectors_per_segment:\n",
    "            # Adding the mfcc and label to our data\n",
    "            data[\"mfcc\"].append(mfcc)\n",
    "            data[\"labels\"].append(data[\"mapping\"].index(genre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We transform the created lists into numpy arrays, so they are easier to handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"mfcc\"] = np.array(data[\"mfcc\"], dtype=np.float32)\n",
    "data[\"labels\"] = np.array(data[\"labels\"], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Flattening the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We flatten the data to make it into a one-dimensional array insted of a 2D array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[\"mfcc\"].shape)\n",
    "flattened_dim=np.prod(data[\"mfcc\"].shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[\"mfcc\"] = data[\"mfcc\"].reshape(-1,flattened_dim)\n",
    "\n",
    "#data[\"mfcc\"] = data[\"mfcc\"].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Splitting training, testing and validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We separate our data into training, validation and test datasets, we define the ratios so we can fine tune them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_length = len(data[\"mfcc\"])\n",
    "train_ratio = 0.7\n",
    "valid_ratio = 0.2\n",
    "test_ratio = 0.1\n",
    "\n",
    "train_size = int(train_ratio*data_length)\n",
    "valid_size = int(valid_ratio*data_length)\n",
    "test_size = int(test_ratio*data_length)\n",
    "\n",
    "X_train = data[\"mfcc\"][:train_size]\n",
    "Y_train = data[\"labels\"][:train_size]\n",
    "X_valid = data[\"mfcc\"][train_size:train_size+valid_size]\n",
    "Y_valid = data[\"labels\"][train_size:train_size+valid_size]\n",
    "X_test = data[\"mfcc\"][train_size+valid_size:]\n",
    "Y_test = data[\"labels\"][train_size+valid_size:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the mean and variance of the training data, then use these values to standerdize the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.asarray(X_train)\n",
    "Y_train=np.asarray(Y_train)\n",
    "X_valid=np.asarray(X_valid)\n",
    "Y_valid=np.asarray(Y_valid)\n",
    "X_test=np.asarray(X_test)\n",
    "Y_test=np.asarray(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(X_train, axis=0)\n",
    "std  = np.std(X_train, axis=0, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train - mean) / std\n",
    "X_valid = (X_valid - mean) / std\n",
    "X_test  = (X_test - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Encoding the labels and performing checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check if each data set has the same number of categories in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = len(np.unique(Y_train))\n",
    "print(\"Validation data has the same number of classes, as the training data:\", nb_classes == len(np.unique(Y_valid)))\n",
    "print(\"Test data has the same number of classes, as the training data:\", nb_classes == len(np.unique(Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We change the dense representation of the classes to one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = to_categorical(Y_train)\n",
    "Y_valid = to_categorical(Y_valid)\n",
    "Y_test  = to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final check if the data has the right shape, mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shapes of the training, validation and test input data:\", X_train.shape, X_valid.shape, X_test.shape)\n",
    "print(\"Shapes of the training, validation and test output data:\", Y_train.shape, Y_valid.shape, Y_test.shape)\n",
    "print(\"Mean values of the training, validation and test input data:\", X_train.mean(), X_valid.mean(), X_test.mean())\n",
    "print(\"Standard deviation of the training, validation and test input data:\", X_train.std(), X_valid.std(), X_test.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([np.array(val) for val in X_train])\n",
    "Y_train = np.array([np.array(val) for val in Y_train])\n",
    "\n",
    "X_train = tf.cast(X_train , dtype=tf.float32)\n",
    "Y_train = tf.cast(Y_train , dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Models\n",
    "For models we decided to use..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "#from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Earlystopping for both of our models, with the same parameter. We restore the best weight in the end of the training and we use a patience of 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    min_delta=0,\n",
    "    patience=5,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    "    start_from_epoch=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first model is an LSTM model. We chose LSTM becasue it is a useful model for timeseries, like music. In the model we stacked multiple LSTMs and between them we put DropOut layers to minimize overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(80, input_shape=(X_train.shape[-2], X_train.shape[-1]),return_sequences=True))\n",
    "#lstm_model.add(Dropout(0.2))\n",
    "#lstm_model.add(LSTM(80, input_shape=(X_train.shape[-2], X_train.shape[-1]),return_sequences=True))\n",
    "lstm_model.add(LSTM(100, input_shape=(X_train.shape[-2], X_train.shape[-1])))\n",
    "lstm_model.add(Dropout(0.2))\n",
    "lstm_model.add(Dense(35, activation='selu',kernel_initializer='he_normal'))\n",
    "lstm_model.add(Dropout(0.35))\n",
    "lstm_model.add(Dense(nb_classes))\n",
    "lstm_model.add(Activation('softmax')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because it is a multi-class classification task we use categorical crossentropy as loss function. We tried different optimizers and we chose ..... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_history = lstm_model.fit(X_train, Y_train,\n",
    "              batch_size=256,\n",
    "              epochs=40,\n",
    "              validation_data=(X_valid, Y_valid),\n",
    "              verbose=1, \n",
    "              callbacks=es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_preds = lstm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(np.argmax(Y_test,1),np.argmax(lstm_preds,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf=confusion_matrix(np.argmax(Y_test,1),np.argmax(lstm_preds,1))\n",
    "sns.heatmap(conf, annot=True, fmt='d', vmax=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv2D(32, (3, 3), activation='relu',kernel_initializer=HeNormal, input_shape=(32, 32, 3)))\n",
    "cnn_model.add(BatchNormalization())\n",
    "#cnn_model.add(Dropout(0.4))\n",
    "cnn_model.add(MaxPool2D((2, 2)))\n",
    "cnn_model.add(Conv2D(64, (3, 3), activation='relu',kernel_initializer=HeNormal))\n",
    "cnn_model.add(BatchNormalization())\n",
    "cnn_model.add(Dropout(0.4))\n",
    "cnn_model.add(MaxPool2D((2, 2)))\n",
    "cnn_model.add(Conv2D(64, (3, 3), activation='relu',kernel_initializer=HeNormal))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "cnn_model.add(BatchNormalization())\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(64, activation='relu',kernel_initializer=HeNormal))\n",
    "cnn_model.add(Dropout(0.3))\n",
    "cnn_model.add(Dense(nb_classes,activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_history = cnn_model.fit(X_train,\n",
    "                    Y_train,\n",
    "                    epochs=40,\n",
    "                    batch_size=64,  \n",
    "                    validation_data=(X_valid, Y_valid),\n",
    "                    verbose=1, \n",
    "                    callbacks=es\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_preds = cnn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(np.argmax(Y_test,1),np.argmax(cnn_preds,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf=confusion_matrix(np.argmax(Y_test,1),np.argmax(cnn_preds,1))\n",
    "sns.heatmap(conf, annot=True, fmt='d', vmax=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2_model = Sequential()\n",
    "cnn2_model.add(Conv1D(filters=20, kernel_size=48, activation='selu', kernel_initializer='he_normal', input_shape=(X_train.shape[-2],X_train.shape[-1]),padding='same'))\n",
    "cnn2_model.add(MaxPooling1D())\n",
    "cnn2_model.add(Dropout(0.4))  \n",
    "cnn2_model.add(Conv1D(filters=20, kernel_size=48, activation='selu', kernel_initializer='he_normal'))\n",
    "cnn2_model.add(Dropout(0.4))\n",
    "cnn2_model.add(LSTM(25, input_shape=(X_train.shape[-2], X_train.shape[-1]),return_sequences=True))\n",
    "cnn2_model.add(LSTM(20, input_shape=(X_train.shape[-2], X_train.shape[-1])))\n",
    "cnn2_model.add(Dropout(0.4))\n",
    "cnn2_model.add(Dense(35, activation='selu',kernel_initializer='he_normal'))\n",
    "cnn2_model.add(Dropout(0.3))\n",
    "cnn2_model.add(Dense(nb_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2_history = cnn2_model.fit(X_train,\n",
    "                    Y_train,\n",
    "                    epochs=80,\n",
    "                    batch_size=128,  \n",
    "                    validation_data=(X_valid, Y_valid),\n",
    "                    verbose=1, \n",
    "                    callbacks=es\n",
    "                    )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPeiS6h3OAXVnkq67zCtqPm",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
